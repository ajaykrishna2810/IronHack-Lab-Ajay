{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca4dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import boxcox\n",
    "pd.options.display.max_rows = 100\n",
    "## Install xlrd package to load Excel files\n",
    "#!conda install openpyxl\n",
    "#!conda install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21419c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = pd.read_csv('file1.csv')\n",
    "file2 = pd.read_csv('file2.csv')#, sep = '\\t')\n",
    "file3 = pd.read_csv('file3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cace465",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe1661",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b483b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "file3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the columns\n",
    "file1.rename(columns={'ST':'State'}, inplace=True) # changed the column name ST into State\n",
    "file2.rename(columns={'ST':'State'}, inplace=True) # changed the column name ST into State\n",
    "file2.rename(columns={'GENDER':'Gender'}, inplace=True) # changed the column name GENDER into Gender\n",
    "file1.rename(columns={'GENDER':'Gender'}, inplace=True) # changed the column name GENDER into Gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40323432",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa27999",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f550bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ab44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arranging all the columns in file 2 amd file 3 in the order provided in file 1\n",
    "file2 = file2[['Customer', 'State', 'Gender', 'Education', 'Customer Lifetime Value', 'Income', 'Monthly Premium Auto', 'Number of Open Complaints', 'Policy Type', 'Vehicle Class', 'Total Claim Amount']]\n",
    "file3 = file3[['Customer', 'State', 'Gender', 'Education', 'Customer Lifetime Value', 'Income', 'Monthly Premium Auto', 'Number of Open Complaints', 'Policy Type', 'Vehicle Class', 'Total Claim Amount']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f8b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb77f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the files file1, file2, file3\n",
    "auto_data_file = pd.concat([file1,file2,file3], axis=0)\n",
    "(auto_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50d0681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the column names to lower\n",
    "auto_data_file.columns=[i.lower() for i in auto_data_file.columns]\n",
    "auto_data_file\n",
    "auto_data_file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ef0045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to reset the index\n",
    "auto_data_file.reset_index() # after that we have two indices\n",
    "\n",
    "\n",
    "# drop some columns which are not so important\n",
    "auto_data_file.drop(['customer'], axis=1, inplace = True)\n",
    "#auto_data_file.drop(['state'], axis=1, inplace = True)\n",
    "auto_data_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1969597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "\n",
    "auto_data_file['gender'].unique()\n",
    "def clean_gender(x):\n",
    "    if x in ['M', 'Male']:\n",
    "        return 'M'\n",
    "    elif x in ['F', 'Femal', 'female']:\n",
    "        return 'F'\n",
    "    else:\n",
    "        return 'NaN'\n",
    "    \n",
    "    \n",
    "    \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a844f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_data_file['gender'] = list(map(clean_gender, auto_data_file['gender'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a34ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_data_file['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98cf123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing unwanted characters from some columns\n",
    "auto_data_file['customer lifetime value'] = auto_data_file['customer lifetime value'].astype('string') # changing column the entries in the column to string\n",
    "auto_data_file['customer lifetime value'] = auto_data_file['customer lifetime value'].str.replace('%', '')\n",
    "auto_data_file['customer lifetime value'] = auto_data_file['customer lifetime value'].astype('float') # changing column the entries in the column to string\n",
    "auto_data_file.info()\n",
    "auto_data_file.head()\n",
    "\n",
    "# truncate/round-up the entries in the column 'customer lifetime value' to integer\n",
    "\n",
    "auto_data_file['customer lifetime value'] = auto_data_file['customer lifetime value'].apply(np.floor)\n",
    "\n",
    "auto_data_file.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b337125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up the  'number of open complaints' column\n",
    "auto_data_file['number of open complaints'] = auto_data_file['number of open complaints'].astype('string') # changing column the entries in the column to string\n",
    "\n",
    "auto_data_file['number of open complaints'].fillna('missing', inplace=True)\n",
    "#auto_data_file['number of open complaints'].unique()  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up 'number of open complaints' column: continued\n",
    "\n",
    "auto_data_file['number of open complaints'] = auto_data_file['number of open complaints'].astype(str).str.replace('(.*)/0/(.*)','0', regex=True)\n",
    "auto_data_file['number of open complaints'] = auto_data_file['number of open complaints'].astype(str).str.replace('(.*)/2/(.*)','2', regex=True)\n",
    "auto_data_file['number of open complaints'] = auto_data_file['number of open complaints'].astype(str).str.replace('(.*)/1/(.*)','1', regex=True)\n",
    "auto_data_file['number of open complaints'] = auto_data_file['number of open complaints'].astype(str).str.replace('(.*)/3/(.*)','3', regex=True)\n",
    "auto_data_file['number of open complaints'] = auto_data_file['number of open complaints'].astype(str).str.replace('(.*)/5/(.*)','5', regex=True)\n",
    "auto_data_file['number of open complaints'] = auto_data_file['number of open complaints'].astype(str).str.replace('(.*)/4/(.*)','4', regex=True)\n",
    "\n",
    "auto_data_file['number of open complaints'] = auto_data_file['number of open complaints'].str.replace('missing','NaN', regex=True)\n",
    "  \n",
    "\n",
    "auto_data_file['number of open complaints'] = auto_data_file['number of open complaints'].astype('float')\n",
    "    \n",
    "auto_data_file['number of open complaints'].unique()  \n",
    "\n",
    "# saving the Monday's work to a new csv\n",
    "\n",
    "auto_data_file.to_csv('Monday.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621cc245",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_data_file['number of open complaints'].unique()\n",
    "auto_data_file.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c94721",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tuesday's work starts here\n",
    "\n",
    "# calling the csv from Monday\n",
    "auto_data_file = pd.read_csv('Monday.csv')\n",
    "auto_data_file.head()\n",
    "\n",
    "# Replacing zeros in the income column with NaN\n",
    "\n",
    "auto_data_file['income'].replace('0', 'NaN', inplace=True) \n",
    "\n",
    "# Replacing null values with the mean\n",
    "\n",
    "def replace_null_value(dataframe, column):\n",
    "    if dataframe[column].dtype != object:\n",
    "        mean = dataframe[column].mean()\n",
    "        dataframe[column].fillna(value=mean, inplace = True)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for clmn in auto_data_file.columns:\n",
    "    replace_null_value(auto_data_file, clmn)\n",
    " \n",
    "\n",
    "\n",
    "auto_data_file.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df8e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucketing the data\n",
    "auto_data_file.rename(columns={'state':'zone'}, inplace=True) # changed the column name state into zone\n",
    "def old_to_new(old, new, columnname):\n",
    "    auto_data_file[columnname].replace(old, new, inplace = True)\n",
    "\n",
    "old_to_new(['Washington', 'WA'], 'East', 'zone') \n",
    "old_to_new(['California', 'Cali'], 'West', 'zone')\n",
    "old_to_new('Oregon', 'North West', 'zone')\n",
    "old_to_new(['Arizona', 'Nevada', 'AZ'], 'Central', 'zone')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_data_file.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747185d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional task on vehicle class: replace Luxury SUV and Luxury Car into Luxury Vehicle\n",
    "old_to_new('Luxury SUV', 'Luxury Vehicle', 'vehicle class')\n",
    "old_to_new('Luxury Car', 'Luxury Vehicle', 'vehicle class')\n",
    "auto_data_file['vehicle class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7cc5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_data_file['income'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1c42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the outliers using the IQR method\n",
    "\n",
    "def remove_outlier(column_name, df):\n",
    "    percentile25 = df[column_name].quantile(0.25)\n",
    "    percentile75 = df[column_name].quantile(0.75)\n",
    "    iqr = percentile75 - percentile25\n",
    "    upper_limit = percentile75 + 1.5 * iqr\n",
    "    lower_limit = percentile25 - 1.5 * iqr\n",
    "    #if i in df[column_name] > upper_limit and df[column_name] < lower_limit:\n",
    "    #    df.replace(i, value = \"Outlier\", inplace = True)\n",
    "    df.replace(to_replace = df[column_name][df[column_name] > upper_limit], value = \"Outlier\", inplace = True)\n",
    "    df.replace(to_replace = df[column_name][df[column_name] < lower_limit], value = \"Outlier\", inplace = True)\n",
    "    number_of_values_replaced = f\"you replaced {df[column_name][df[column_name] > upper_limit].shape[0] + df[column_name][df[column_name] < lower_limit].shape[0]} outlier values with the string Outlier\"\n",
    "    return number_of_values_replaced\n",
    "  \n",
    "remove_outlier('income', auto_data_file) \n",
    "remove_outlier('customer lifetime value', auto_data_file) \n",
    "remove_outlier('monthly premium auto', auto_data_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da68706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auto_data_file['monthly premium auto'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0bcd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the Tuesday's work to a new csv\n",
    "\n",
    "auto_data_file.to_csv('Tuesday.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
